<div align="center">
    <h1>Awesome RAG in Computer Vision</h1>
    <a href="https://awesome.re"><img src="https://awesome.re/badge.svg"/></a>
</div>

\
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/hee9joon/Awesome-Diffusion-Models) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Made With Love](https://img.shields.io/badge/Made%20With-Love-red.svg)](https://github.com/chetanraj/awesome-github-badges)



This repo aims to record advanced papers on Retrieval Augmented Generation (RAG) in Computer Vision.

We strongly encourage the researchers that want to promote their fantastic work to the RAG for Vision to make pull request to update their paper's information!

## Contents

- [Resources](#resources)
  - [Workshops and Tutorials](#workshops-and-tutorials)
- [Papers](#papers)
  - [Survey and Benchmark](#survey-and-benchmark)

# Resources 

## Workshops and Tutorials


# Papers 

## Survey and Benchmark 

## RAG for Vision

### 1 Visual Understanding 

#### 1.1 (Long) Video Understanding

**Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension**  \
Yongdong Luo, Xiawu Zheng, Xiao Yang, Guilin Li, Haojia Lin, Jinfa Huang, Jiayi Ji, Fei Chao, Jiebo Luo, Rongrong Ji \
Arxiv 24 – Nov 2024 [[paper](https://arxiv.org/pdf/2411.13093)]

**ViTA: An Efficient Video-to-Text Algorithm using VLM for RAG-based Video Analysis System**  \
Md Adnan Arefeen, Biplob Debnath, Md Yusuf Sarwar Uddin, Srimat Chakradhar \
CVPRW 24 [[paper](https://aclanthology.org/2024.emnlp-main.62.pdf)]

**iRAG: Advancing RAG for Videos with an Incremental Approach**  \
Md Adnan Arefeen, Md Yusuf Sarwar Uddin, Biplob Debnath, Srimat Chakradhar \
CIKM 24 [[paper](https://dl.acm.org/doi/pdf/10.1145/3627673.3680088?casa_token=CDXIXZP0y9QAAAAA:obaFKtQODdGsI3pB22GWuGH2dODwF7N0dj1dl58WfSwavmvrp_1eeaHXj6c2XCQyt-9vF1r1QrUd)]

#### 1.2 Visual Spacial Understanding

**RAG-Guided Large Language Models for Visual Spatial Description with Adaptive Hallucination Corrector**  \
Jun Yu, Yunxiang Zhang, Zerui Zhang, Zhao Yang, Gongpeng Zhao, Fengzhao Sun, Fanrui Zhang, Qingsong Liu, Jianqing Sun, Jiaen Liang, Yaohui Zhang \
ACM MM 24 [[paper](https://dl.acm.org/doi/abs/10.1145/3664647.3688990?casa_token=SlLR5jgRRkgAAAAA:DzC124tFMWQSMYkKRGkPTwU-aaT7TSv_iVjE-dsZtbna9j3zCYX1A6qcfgmpEKTms8DoZDgplc5u8g)]

#### 1.3 Multi-modal

**M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding**  \
Jaemin Cho, Debanjan Mahata, Ozan Irsoy, Yujie He, Mohit Bansal  \
Arxiv 24 – Nov 2024 [[paper](https://arxiv.org/pdf/2410.21943)]

**VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents**  \
Shi Yu, Chaoyue Tang, Bokai Xu, Junbo Cui, Junhao Ran, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun  \
Arxiv 24 – Oct 2024 [[paper](https://arxiv.org/abs/2410.10594)]

**RoRA-VLM: Robust Retrieval Augmentation for Vision Language Models**  \
Jingyuan Qi, Zhiyang Xu, Rulin Shao, Yang Chen, Jin Di, Yu Cheng, Qifan Wang, Lifu Huang  \
Arxiv 24 - Oct 24 [[paper](https://arxiv.org/pdf/2410.08876)]

**Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial Applications**  \
Monica Riedler, Stefan Langer  \
Arxiv 24 – Oct 2024 [[paper](https://arxiv.org/pdf/2410.21943)]

**SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information**  \
Jiashuo Sun, Jihai Zhang, Yucheng Zhou, Zhaochen Su, Xiaoye Qu, Yu Cheng  \
EMNLP 24 – Sep 2024 [[paper](https://arxiv.org/pdf/2409.14083)]

**ColPali: Efficient Document Retrieval with Vision Language Models**  \
Manuel Faysse, Hugues Sibille, Tony Wu, Bilel Omrani, Gautier Viaud, Céline Hudelot, Pierre Colombo  \
Arxiv 24 – Jul 2024 [[paper](https://arxiv.org/pdf/2407.01449)]

**MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation via Knowledge-enhanced Reranking and Noise-injected Training**  \
Zhanpeng Chen, Chengjin Xu, Yiyan Qi, Jian Guo  \
Arxiv 24 – Jul 2024 [[paper](https://arxiv.org/pdf/2409.14083)]

**RAVEN: Multitask Retrieval Augmented Vision-Language Learning**  \
Varun Nagaraj Rao, Siddharth Choudhary, Aditya Deshpande, Ravi Kumar Satzoda, Srikar Appalaraju  \
Arxiv 24 - Jun 2024 [[paper](https://arxiv.org/pdf/2406.19150)]

**SearchLVLMs: A Plug-and-Play Framework for Augmenting Large Vision-Language Models by Searching Up-to-Date Internet Knowledge**  \
Chuanhao Li, Zhen Li, Chenchen Jing, Shuo Liu, Wenqi Shao, Yuwei Wu, Ping Luo, Yu Qiao, Kaipeng Zhang  \
Arxiv 24 – May 2024 [[paper](https://arxiv.org/pdf/2405.14554)]

**Retrieval Meets Reasoning: Even High-school Textbook Knowledge Benefits Multimodal Reasoning**  \
Cheng Tan, Jingxuan Wei, Linzhuang Sun, Zhangyang Gao, Siyuan Li, Bihui Yu, Ruifeng Guo, Stan Z. Li  \
Arxiv 24 – Apr 2024 [[paper](https://arxiv.org/pdf/2409.14083)]

**RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition**  \
Ziyu Liu, Zeyi Sun, Yuhang Zang, Wei Li, Pan Zhang, Xiaoyi Dong, Yuanjun Xiong, Dahua Lin, Jiaqi Wang  \
Arxiv 24 – Mar 2024 [[paper](https://arxiv.org/pdf/2409.14083)]

**Fine-grained Late-interaction Multi-modal Retrieval for Retrieval Augmented Visual Question Answering**  \
Weizhe Lin, Jinghong Chen, Jingbiao Mei, Alexandru Coca, Bill Byrne  \
NIPS 23 - Oct 2023 [[paper](https://arxiv.org/pdf/2309.17133)]

**Retrieval-based Knowledge Augmented Vision Language Pre-training**  \
Jiahua Rao, Zifei Shan, Longpo Liu, Yao Zhou, Yuedong Yang  \
ACMMM 23 - Apr 2023 [[paper](https://arxiv.org/pdf/2304.13923)]

**ReVeaL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory**  \
Ziniu Hu, Ahmet Iscen, Chen Sun, Zirui Wang, Kai-Wei Chang, Yizhou Sun, Cordelia Schmid, David A. Ross, Alireza Fathi  \
CVPR 23 - Apr 2023 [[paper](https://arxiv.org/pdf/2212.05221)]

**Learning Customized Visual Models with Retrieval-Augmented Knowledge**  \
Haotian Liu, Kilho Son, Jianwei Yang, Ce Liu, Jianfeng Gao, Yong Jae Lee, Chunyuan Li  \
CVPR 23 - Jan 2023 [[paper](https://arxiv.org/pdf/2301.07094)]

#### 1.4 Medical Vision

**Mmed-rag: Versatile multimodal rag system for medical vision language models**  \
Peng Xia, Kangyu Zhu, Haoran Li, Tianze Wang, Weijia Shi, Sheng Wang, Linjun Zhang, James Zou, Huaxiu Yao \
Arxiv 24 – Oct 2024 [[paper](https://arxiv.org/pdf/2410.13085)]

**Rule: Reliable multimodal rag for factuality in medical vision language models**  \
Peng Xia, Kangyu Zhu, Haoran Li, Hongtu Zhu, Yun Li, Gang Li, Linjun Zhang, Huaxiu Yao \
EMNLP 24 [[paper](https://aclanthology.org/2024.emnlp-main.62.pdf)]

### 2 Visual Generation 

#### 2.1 Image (Video) Generation

**Retrieval-Augmented Diffusion Models** \
Andreas Blattmann, Robin Rombach, Kaan Oktay, Jonas Müller, Björn Ommer \
NIPS 22 [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/62868cc2fc1eb5cdf321d05b4b88510c-Paper-Conference.pdf)]

**Label-Retrieval-Augmented Diffusion Models for Learning from Noisy Labels** \
Jian Chen, Ruiyi Zhang, Tong Yu, Rohan Sharma, Zhiqiang Xu, Tong Sun, Changyou Chen \
NIPS 23 [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/d191ba4c8923ed8fd8935b7c98658b5f-Paper-Conference.pdf)]

**CPR: Retrieval Augmented Generation for Copyright Protection** \
Aditya Golatkar, Alessandro Achille, Luca Zancato, Yu-Xiang Wang, Ashwin Swaminathan, Stefano Soatto \
CVPR 23 [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Golatkar_CPR_Retrieval_Augmented_Generation_for_Copyright_Protection_CVPR_2024_paper.pdf)]

**BrainRAM: Cross-Modality Retrieval-Augmented Image Reconstruction from Human Brain Activity** \
Dian Xie, Peiang Zhao, Jiarui Zhang, Kangqi Wei, Xiaobao Ni, Jiong Xia \
MM 24 [[paper](https://dl.acm.org/doi/pdf/10.1145/3664647.3681296)]

**Animate-A-Story: Storytelling with Retrieval-Augmented Video Generation** \
He Yingqing, Xia Menghan, Chen Haoxin, Cun Xiaodong, Gong Yuan, Xing Jinbo, Zhang Yong, Wang Xintao, Weng Chao, Shan Ying, Chen Qifeng \
Arxiv 23 [[paper](https://arxiv.org/pdf/2307.06940)]

**RealGen: Retrieval Augmented Generation for Controllable Traffic Scenarios** \
Wenhao Ding, Yulong Cao, Ding Zhao, Chaowei Xiao, Marco Pavone \
ECCV 24 [[paper](https://arxiv.org/pdf/2312.13303)]

**Grounding Language Models for Visual Entity Recognition** \
Zilin Xiao, Ming Gong, Paola Cascante-Bonilla, Xingyao Zhang, Jie Wu, Vicente Ordonez \
ECCV 24 [[paper](https://arxiv.org/pdf/2402.18695)]

**GarmentAligner: Text-to-Garment Generation via Retrieval-augmented Multi-level Corrections** \
Shiyue Zhang, Zheng Chong, Xujie Zhang, Hanhui Li, Yuhao Cheng, Yiqiang Yan, Xiaodan Liang \
ECCV 24 [[paper](https://arxiv.org/pdf/2408.12352)]

**Retrieval-Augmented Layout Transformer for Content-Aware Layout Generation** \
Daichi Horita, Naoto Inoue, Kotaro Kikuchi, Kota Yamaguchi, Kiyoharu Aizawa \
CVPR 24 [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Horita_Retrieval-Augmented_Layout_Transformer_for_Content-Aware_Layout_Generation_CVPR_2024_paper.pdf)]

**The Neglected Tails in Vision-Language Models** \
Shubham Parashar, Zhiqiu Lin, Tian Liu, Xiangjue Dong, Yanan Li, Deva Ramanan, James Caverlee, Shu Kong \
CVPR 24 [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Horita_Retrieval-Augmented_Layout_Transformer_for_Content-Aware_Layout_Generation_CVPR_2024_paper.pdf)]

**Prompt Expansion for Adaptive Text-to-Image Generation** \
Siddhartha Datta, Alexander Ku, Deepak Ramachandran, Peter Anderson \
ACL 24 [[paper](https://arxiv.org/pdf/2312.16720)]

**The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention** \
Yixin Wan, Di Wu, Haoran Wang, Kai-Wei Chang \
EMNLP 24 [[paper](https://arxiv.org/pdf/2407.00377)]

**Diffusion Based Augmentation for Captioning and Retrieval in Cultural Heritage** \
Dario Cioni, Lorenzo Berlincioni, Federico Becattini, Alberto del Bimbo \
ICCV 23 [[paper](https://openaccess.thecvf.com/content/ICCV2023W/e-Heritage/papers/Cioni_Diffusion_Based_Augmentation_for_Captioning_and_Retrieval_in_Cultural_Heritage_ICCVW_2023_paper.pdf)]

**ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model** \
Mingyuan Zhang, Xinying Guo, Liang Pan, Zhongang Cai, Fangzhou Hong, Huirong Li, Lei Yang, Ziwei Liu \
ICCV 23 [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ReMoDiffuse_Retrieval-Augmented_Motion_Diffusion_Model_ICCV_2023_paper.pdf)]

**Re-imagen: Retrieval-augmented text-to-image generator** \
Wenhu Chen, Hexiang Hu, Chitwan Saharia, William W. Cohen \
Arxiv 22 [[paper](https://arxiv.org/pdf/2209.14491)]

**Instruct-Imagen: Image Generation with Multi-modal Instruction** \
Hexiang Hu, Kelvin C.K. Chan, Yu-Chuan Su, Wenhu Chen, Yandong Li, Kihyuk Sohn, Yang Zhao, Xue Ben, Boqing Gong, William Cohen, Ming-Wei Chang, Xuhui Jia \
CVPR 24 [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Hu_Instruct-Imagen_Image_Generation_with_Multi-modal_Instruction_CVPR_2024_paper.pdf)]

#### 2.2 3D Generation

**Phidias: A Generative Model for Creating 3D Content from Text, Image, and 3D Conditions with Reference-Augmented Diffusion** \
Zhenwei Wang, Tengfei Wang, Zexin He, Gerhard Hancke, Ziwei Liu, Rynson W.H. Lau \
Arxiv 24 - Sep 2024 [[paper](https://arxiv.org/pdf/2409.11406)]

**Retrieval-Augmented Score Distillation for Text-to-3D Generation** \
Junyoung Seo, Susung Hong, Wooseok Jang, Ines Hyeonsu Kim, Minseop Kwak, Doyup Lee, Seungryong Kim \
ICML 24 [[paper](https://arxiv.org/pdf/2402.02972)]

**Diorama: Unleashing Zero-shot Single-view 3D Scene Modeling** \
Qirui Wu, Denys Iliash, Daniel Ritchie, Manolis Savva, Angel X. Chang \
Arxiv 24 - Nov 2024 [[paper](https://arxiv.org/pdf/2411.19492)]

**Interaction-based Retrieval-augmented Diffusion Models for Protein-specific 3D Molecule Generation** \
Zhilin Huang, Ling Yang, Xiangxin Zhou, Chujun Qin, Yijie Yu, Xiawu Zheng, Zikun Zhou, Wentao Zhang, Yu Wang, Wenming Yang \
ICML 24 [[paper](https://openreview.net/pdf?id=eejhD9FCP3)]

### 3. Embodied AI

**ENWAR: A RAG-empowered Multi-Modal LLM Framework for Wireless Environment Perception**  \
Ahmad M. Nazar, Abdulkadir Celik, Mohamed Y. Selim, Asmaa Abdallah, Daji Qiao, Ahmed M. Eltawil \
Arxiv 24 - Oct 2024 [[paper](https://arxiv.org/pdf/2410.18104)]

**Embodied-RAG: General Non-parametric Embodied Memory for Retrieval and Generation**  \
Quanting Xie, So Yeon Min, Tianyi Zhang, Kedi Xu, Aarav Bajaj, Ruslan Salakhutdinov, Matthew Johnson-Roberson, Yonatan Bisk \
Arxiv 24 - Oct 2024 [[paper](https://arxiv.org/pdf/2409.18313)]

**RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model**  \
Jianhao Yuan, Shuyang Sun, Daniel Omeiza, Bo Zhao, Paul Newman, Lars Kunze, Matthew Gadd \
Arxiv 24 - May 2024 [[paper](https://arxiv.org/abs/2402.10828)]
